\documentclass[12pt]{article}
\usepackage{enumitem}
%\usepackage[T1]{fontenc}
\usepackage[auth-sc,affil-sl]{authblk}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{color}
\usepackage[toc,page]{appendix}
%\usepackage{enumerate}
\usepackage[round]{natbib}
%\usepackage{url} % not crucial - just used below for the URL 
%\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{hyperref}
\usepackage{alltt}
\usepackage{listings}
\usepackage{array}
\usepackage[noline, boxed, linesnumbered, procnumbered, titlenumbered]{algorithm2e}
%\usepackage[firstpage]{draftwatermark}
\usepackage[margin=1in]{geometry}  %%jcgs has own margins
\usepackage{lmodern}
\usepackage{caption}
\usepackage{subcaption}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\appdxref}[1]{Appendix~\ref{#1}}
\newcommand{\tblref}[1]{Table~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\thmref}[1]{Theorem~\ref{#1}}
\newcommand{\algref}[1]{Algorithm~\ref{#1}}
\newcommand{\funref}[1]{Function~\ref{#1}}
\newcommand{\listingref}[1]{Listing~\ref{#1}}

\newcommand{\eg}{{\em e.g.}}
\newcommand{\ith}{$i^{th}$}
\newcommand{\cut}[1]{}
\newcommand{\todo}[1]{{{\color{red}{[#1]}}}}

\newcommand{\spd}{\fontfamily{cmr}\textsc{\small StratPD}}
\newcommand{\cspd}{\fontfamily{cmr}\textsc{\small CatStratPD}}
\newcommand{\xnc}{$x_{\overline{c}}$}
\newcommand{\xnC}{$x_{\overline{C}}$}

\setlist[enumerate]{itemsep=-1mm}

% DON'T change margins - should be 1 inch all around.
\cut{
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%
}

\begin{document}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf foo}

  \author{Terence Parr and James D. Wilson\\
      University of San Francisco\\
}
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Title}
\end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
dsf
\end{abstract}

\noindent%
{\it Keywords:} feature importance, partial dependence, model interpretability, linear models
%\vfill

%\newpage
%\spacingset{1.5} % DON'T change the spacing!
\section{Introduction}
\label{sec:intro}

For true function $y = f(\bf x)$ and ${\bf x} = [x_1, \ldots, x_p]$ and ${\bf X} = [x^{(1)}, \ldots, x^{(n)}]$ (skipping bolding the vectors there).  Training data is pair ($\bf X, y$).

Partial dependence of $y$ on  $x_i$ at some $x$ is the cumulative sum up to $x$ from $min(x_i)$:

\[
\text{\it PD}_i(x) = \int_{min(x_i)}^x \frac{\partial y}{\partial x_i} dx_i
\]

Software currently relies on something like:

\[
n \overline {\bf y} = \int_{min(x_1)}^{max(x_1)} \text{\it PD}_1(x) + \ldots + \int_{min(x_p)}^{max(x_p)} \text{\it PD}_p(x)
\]

Let width of $x_i$ var be $w_i = max(x_1)-min(x_1)$ then by mean value theorem of calculus:

\[
n \overline {\bf y} = w_1\overline{\text{\it PD}_1(x)}\big |_{min(x_1)}^{max(x_1)} + \ldots + w_p\overline{\text{\it PD}_p(x)}\big |_{min(x_p)}^{max(x_p)}
\]

Need to convert units so it's ``instances $\times$ $y$ units,'' not ``$x_i$ units $\times$ $y$ units'' so multiply by $\frac{n}{w_i}$:

\[
n \overline {\bf y} = \frac{n}{w_1} w_1\overline{\text{\it PD}_1(x)}\big |_{min(x_1)}^{max(x_1)} + \ldots + \frac{n}{w_p} w_p\overline{\text{\it PD}_p(x)}\big |_{min(x_p)}^{max(x_p)}
\]

(algebra seems sketchy there.) Simplifying:

\[
n \overline {\bf y} = n\overline{\text{\it PD}_1(x)}\big |_{min(x_1)}^{max(x_1)} + \ldots + n \overline{\text{\it PD}_p(x)}\big |_{min(x_p)}^{max(x_p)}
\]

The $n$'s cancel:

\[
\overline {\bf y} = \overline{\text{\it PD}_1(x)}\big |_{min(x_1)}^{max(x_1)} + \ldots + \overline{\text{\it PD}_p(x)}\big |_{min(x_p)}^{max(x_p)}
\]

Basically we gotta show that areas under all $\text{\it PD}_i(x)$ sum to $\overline{\bf y}$ if no noise and exogenous vars.

Proof will likely hinge on

\[
\overline {\bf y} \le \overline{\text{\it PD}_i(x)}\big |_{min(x_i)}^{max(x_i)} ~\forall\, i
\]


\bibliographystyle{apalike}

\bibliography{stratpd}
\end{document}